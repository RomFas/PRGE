{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Detection Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify dataset/working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"WN18\"\n",
    "os.chdir('..')\n",
    "dataset_wd = os.getcwd() + \"/data/\" + dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load entity-to-id and relation-to-id directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dataset_wd + \"/relation2id.txt\",\"r\")\n",
    "relation2id = {}\n",
    "relation_num = 0\n",
    "for line in f:\n",
    "    seg = line.strip().split()\n",
    "    relation2id[seg[0]] = int(seg[1])\n",
    "    relation_num += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dataset_wd + \"/entity2id.txt\",\"r\")\n",
    "entity2id = {}\n",
    "for line in f:\n",
    "    seg = line.strip().split()\n",
    "    entity2id[seg[0]] = int(seg[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train dataset triples, as well as the negative triples (of different ratios):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt_pos = pd.read_csv(dataset_wd + \"/train.txt\", sep = '\\t', header = None, dtype=str)\n",
    "train_dt_pos.columns = [\"e1\", \"e2\", \"r\"]\n",
    "\n",
    "train_dt_neg_10 = pd.read_csv(dataset_wd + \"/\" + dataset + \"10%/neg_triples.txt\", sep = '\\t', header = None, dtype=str)\n",
    "train_dt_neg_10.columns = [\"e1\", \"e2\", \"r\"]\n",
    "\n",
    "train_dt_neg_20 = pd.read_csv(dataset_wd + \"/\" + dataset + \"20%/neg_triples.txt\", sep = '\\t', header = None, dtype=str)\n",
    "train_dt_neg_20.columns = [\"e1\", \"e2\", \"r\"]\n",
    "\n",
    "train_dt_neg_40 = pd.read_csv(dataset_wd + \"/\" + dataset + \"40%/neg_triples.txt\", sep = '\\t', header = None, dtype=str)\n",
    "train_dt_neg_40.columns = [\"e1\", \"e2\", \"r\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into subject, object and relation arrays for each of the aforementioned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities1_pos = np.asarray(train_dt_pos['e1'].apply(lambda x: entity2id[x]))\n",
    "entities2_pos = np.asarray(train_dt_pos['e2'].apply(lambda x: entity2id[x]))\n",
    "relations_pos = np.asarray(train_dt_pos['r'].apply(lambda x: relation2id[x]))\n",
    "\n",
    "entities1_neg_10 = np.asarray(train_dt_neg_10['e1'].apply(lambda x: entity2id[x]))\n",
    "entities2_neg_10 = np.asarray(train_dt_neg_10['e2'].apply(lambda x: entity2id[x]))\n",
    "relations_neg_10 = np.asarray(train_dt_neg_10['r'].apply(lambda x: relation2id[x]))\n",
    "\n",
    "entities1_neg_20 = np.asarray(train_dt_neg_20['e1'].apply(lambda x: entity2id[x]))\n",
    "entities2_neg_20 = np.asarray(train_dt_neg_20['e2'].apply(lambda x: entity2id[x]))\n",
    "relations_neg_20 = np.asarray(train_dt_neg_20['r'].apply(lambda x: relation2id[x]))\n",
    "\n",
    "entities1_neg_40 = np.asarray(train_dt_neg_40['e1'].apply(lambda x: entity2id[x]))\n",
    "entities2_neg_40 = np.asarray(train_dt_neg_40['e2'].apply(lambda x: entity2id[x]))\n",
    "relations_neg_40 = np.asarray(train_dt_neg_40['r'].apply(lambda x: relation2id[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Embeddings and Calculate Scores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TransE\n",
    "Load TransE embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransE_relation_emb_10 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/relation2vec10_l_0.01\")\n",
    "TransE_entity_emb_10 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/entity2vec10_l_0.01\")\n",
    "\n",
    "TransE_relation_emb_20 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/relation2vec20_l_0.01\")\n",
    "TransE_entity_emb_20 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/entity2vec20_l_0.01\")\n",
    "\n",
    "TransE_relation_emb_40 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/relation2vec40_l_0.01\")\n",
    "TransE_entity_emb_40 = np.loadtxt(os.getcwd() + \"/TransE/\" + dataset + \"_Embeddings/entity2vec40_l_0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate TransE scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransE_score_pos_10 = np.linalg.norm(TransE_entity_emb_10[entities1_pos, :] + TransE_relation_emb_10[relations_pos, :] - TransE_entity_emb_10[entities2_pos, :], axis = 1)\n",
    "TransE_score_neg_10 = np.linalg.norm(TransE_entity_emb_10[entities1_neg_10, :] + TransE_relation_emb_10[relations_neg_10, :] - TransE_entity_emb_10[entities2_neg_10, :], axis = 1)\n",
    "\n",
    "TransE_score_pos_20 = np.linalg.norm(TransE_entity_emb_20[entities1_pos, :] + TransE_relation_emb_20[relations_pos, :] - TransE_entity_emb_20[entities2_pos, :], axis = 1)\n",
    "TransE_score_neg_20 = np.linalg.norm(TransE_entity_emb_20[entities1_neg_20, :] + TransE_relation_emb_20[relations_neg_20, :] - TransE_entity_emb_20[entities2_neg_20, :], axis = 1)\n",
    "\n",
    "TransE_score_pos_40 = np.linalg.norm(TransE_entity_emb_40[entities1_pos, :] + TransE_relation_emb_40[relations_pos, :] - TransE_entity_emb_40[entities2_pos, :], axis = 1)\n",
    "TransE_score_neg_40 = np.linalg.norm(TransE_entity_emb_40[entities1_neg_40, :] + TransE_relation_emb_40[relations_neg_40, :] - TransE_entity_emb_40[entities2_neg_40, :], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PTransE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PTransE embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTransE_relation_emb_10 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/relation2vec10_l_0.01\")\n",
    "PTransE_entity_emb_10 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/entity2vec10_l_0.01\")\n",
    "\n",
    "PTransE_relation_emb_20 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/relation2vec20_l_0.01\")\n",
    "PTransE_entity_emb_20 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/entity2vec20_l_0.01\")\n",
    "\n",
    "PTransE_relation_emb_40 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/relation2vec40_l_0.01\")\n",
    "PTransE_entity_emb_40 = np.loadtxt(os.getcwd() + \"/PTransE/PTransE_add/\" + dataset + \"_Embeddings/entity2vec40_l_0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate PTransE scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTransE_score_pos_10 = np.linalg.norm(PTransE_entity_emb_10[entities1_pos, :] + PTransE_relation_emb_10[relations_pos, :] - PTransE_entity_emb_10[entities2_pos, :], axis = 1)\n",
    "PTransE_score_neg_10 = np.linalg.norm(PTransE_entity_emb_10[entities1_neg_10, :] + PTransE_relation_emb_10[relations_neg_10, :] - PTransE_entity_emb_10[entities2_neg_10, :], axis = 1)\n",
    "\n",
    "PTransE_score_pos_20 = np.linalg.norm(PTransE_entity_emb_20[entities1_pos, :] + PTransE_relation_emb_20[relations_pos, :] - PTransE_entity_emb_20[entities2_pos, :], axis = 1)\n",
    "PTransE_score_neg_20 = np.linalg.norm(PTransE_entity_emb_20[entities1_neg_20, :] + PTransE_relation_emb_20[relations_neg_20, :] - PTransE_entity_emb_20[entities2_neg_20, :], axis = 1)\n",
    "\n",
    "PTransE_score_pos_40 = np.linalg.norm(PTransE_entity_emb_40[entities1_pos, :] + PTransE_relation_emb_40[relations_pos, :] - PTransE_entity_emb_40[entities2_pos, :], axis = 1)\n",
    "PTransE_score_neg_40 = np.linalg.norm(PTransE_entity_emb_40[entities1_neg_40, :] + PTransE_relation_emb_40[relations_neg_40, :] - PTransE_entity_emb_40[entities2_neg_40, :], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CKRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CKRL Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKRL_relation_emb_10 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/relation2vec10_l_0.01\")\n",
    "CKRL_entity_emb_10 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/entity2vec10_l_0.01\")\n",
    "\n",
    "CKRL_relation_emb_20 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/relation2vec20_l_0.01\")\n",
    "CKRL_entity_emb_20 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/entity2vec20_l_0.01\")\n",
    "\n",
    "CKRL_relation_emb_40 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/relation2vec40_l_0.01\")\n",
    "CKRL_entity_emb_40 = np.loadtxt(os.getcwd() + \"/CKRL/\" + dataset + \"_Embeddings/entity2vec40_l_0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate CKRL scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKRL_score_pos_10 = np.linalg.norm(CKRL_entity_emb_10[entities1_pos, :] + CKRL_relation_emb_10[relations_pos, :] - CKRL_entity_emb_10[entities2_pos, :], axis = 1)\n",
    "CKRL_score_neg_10 = np.linalg.norm(CKRL_entity_emb_10[entities1_neg_10, :] + CKRL_relation_emb_10[relations_neg_10, :] - CKRL_entity_emb_10[entities2_neg_10, :], axis = 1)\n",
    "\n",
    "CKRL_score_pos_20 = np.linalg.norm(CKRL_entity_emb_20[entities1_pos, :] + CKRL_relation_emb_20[relations_pos, :] - CKRL_entity_emb_20[entities2_pos, :], axis = 1)\n",
    "CKRL_score_neg_20 = np.linalg.norm(CKRL_entity_emb_20[entities1_neg_20, :] + CKRL_relation_emb_20[relations_neg_20, :] - CKRL_entity_emb_20[entities2_neg_20, :], axis = 1)\n",
    "\n",
    "CKRL_score_pos_40 = np.linalg.norm(CKRL_entity_emb_40[entities1_pos, :] + CKRL_relation_emb_40[relations_pos, :] - CKRL_entity_emb_40[entities2_pos, :], axis = 1)\n",
    "CKRL_score_neg_40 = np.linalg.norm(CKRL_entity_emb_40[entities1_neg_40, :] + CKRL_relation_emb_40[relations_neg_40, :] - CKRL_entity_emb_40[entities2_neg_40, :], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRGE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PRGE Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRGE_relation_emb_10 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec10_l_0.01_lambda_1\")\n",
    "PRGE_entity_emb_10 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec10_l_0.01_lambda_1\")\n",
    "\n",
    "PRGE_relation_emb_20 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec20_l_0.01_lambda_1\")\n",
    "PRGE_entity_emb_20 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec20_l_0.01_lambda_1\")\n",
    "\n",
    "PRGE_relation_emb_40 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec40_l_0.01_lambda_1\")\n",
    "PRGE_entity_emb_40 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec40_l_0.01_lambda_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate PRGE scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRGE_score_pos_10 = np.linalg.norm(PRGE_entity_emb_10[entities1_pos, :] + PRGE_relation_emb_10[relations_pos, :] - PRGE_entity_emb_10[entities2_pos, :], axis = 1)\n",
    "PRGE_score_neg_10 = np.linalg.norm(PRGE_entity_emb_10[entities1_neg_10, :] + PRGE_relation_emb_10[relations_neg_10, :] - PRGE_entity_emb_10[entities2_neg_10, :], axis = 1)\n",
    "\n",
    "PRGE_score_pos_20 = np.linalg.norm(PRGE_entity_emb_20[entities1_pos, :] + PRGE_relation_emb_20[relations_pos, :] - PRGE_entity_emb_20[entities2_pos, :], axis = 1)\n",
    "PRGE_score_neg_20 = np.linalg.norm(PRGE_entity_emb_20[entities1_neg_20, :] + PRGE_relation_emb_20[relations_neg_20, :] - PRGE_entity_emb_20[entities2_neg_20, :], axis = 1)\n",
    "\n",
    "PRGE_score_pos_40 = np.linalg.norm(PRGE_entity_emb_40[entities1_pos, :] + PRGE_relation_emb_40[relations_pos, :] - PRGE_entity_emb_40[entities2_pos, :], axis = 1)\n",
    "PRGE_score_neg_40 = np.linalg.norm(PRGE_entity_emb_40[entities1_neg_40, :] + PRGE_relation_emb_40[relations_neg_40, :] - PRGE_entity_emb_40[entities2_neg_40, :], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRGE-Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PRGE-scaled Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRGE_scaled_relation_emb_10 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec10_l_0.01_lambda_5\")\n",
    "PRGE_scaled_entity_emb_10 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec10_l_0.01_lambda_5\")\n",
    "\n",
    "PRGE_scaled_relation_emb_20 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec20_l_0.01_lambda_5\")\n",
    "PRGE_scaled_entity_emb_20 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec20_l_0.01_lambda_5\")\n",
    "\n",
    "PRGE_scaled_relation_emb_40 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/relation2vec40_l_0.01_lambda_5\")\n",
    "PRGE_scaled_entity_emb_40 = np.loadtxt(os.getcwd() + \"/PaTyBRED-TransE/\" + dataset + \"_Embeddings/entity2vec40_l_0.01_lambda_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRGE_scaled_score_pos_10 = np.linalg.norm(PRGE_scaled_entity_emb_10[entities1_pos, :] + PRGE_scaled_relation_emb_10[relations_pos, :] - PRGE_scaled_entity_emb_10[entities2_pos, :], axis = 1)\n",
    "PRGE_scaled_score_neg_10 = np.linalg.norm(PRGE_scaled_entity_emb_10[entities1_neg_10, :] + PRGE_scaled_relation_emb_10[relations_neg_10, :] - PRGE_scaled_entity_emb_10[entities2_neg_10, :], axis = 1)\n",
    "\n",
    "PRGE_scaled_score_pos_20 = np.linalg.norm(PRGE_scaled_entity_emb_20[entities1_pos, :] + PRGE_scaled_relation_emb_20[relations_pos, :] - PRGE_scaled_entity_emb_20[entities2_pos, :], axis = 1)\n",
    "PRGE_scaled_score_neg_20 = np.linalg.norm(PRGE_scaled_entity_emb_20[entities1_neg_20, :] + PRGE_scaled_relation_emb_20[relations_neg_20, :] - PRGE_scaled_entity_emb_20[entities2_neg_20, :], axis = 1)\n",
    "\n",
    "PRGE_scaled_score_pos_40 = np.linalg.norm(PRGE_scaled_entity_emb_40[entities1_pos, :] + PRGE_scaled_relation_emb_40[relations_pos, :] - PRGE_scaled_entity_emb_40[entities2_pos, :], axis = 1)\n",
    "PRGE_scaled_score_neg_40 = np.linalg.norm(PRGE_scaled_entity_emb_40[entities1_neg_40, :] + PRGE_scaled_relation_emb_40[relations_neg_40, :] - PRGE_scaled_entity_emb_40[entities2_neg_40, :], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PatyBRED Confidence values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PaTyBRED_10 = pd.read_csv(dataset_wd + \"/\" + dataset + \"_features_10%.csv\", header = None, sep = '\\t')\n",
    "PaTyBRED_10.columns = ['Subject', 'Relation', 'Object', 'Label', 'Confidence']\n",
    "PaTyBRED_10 = PaTyBRED_10[PaTyBRED_10.Label == 1]\n",
    "\n",
    "PaTyBRED_20 = pd.read_csv(dataset_wd + \"/\" + dataset + \"_features_20%.csv\", header = None, sep = '\\t')\n",
    "PaTyBRED_20.columns = ['Subject', 'Relation', 'Object', 'Label', 'Confidence']\n",
    "PaTyBRED_20 = PaTyBRED_20[PaTyBRED_20.Label == 1]\n",
    "\n",
    "PaTyBRED_40 = pd.read_csv(dataset_wd + \"/\" + dataset + \"_features_40%.csv\", header = None, sep = '\\t')\n",
    "PaTyBRED_40.columns = ['Subject', 'Relation', 'Object', 'Label', 'Confidence']\n",
    "PaTyBRED_40 = PaTyBRED_40[PaTyBRED_40.Label == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Starting dataframes for positives/negatives (across all different noise levels):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pos = np.ones(TransE_score_pos_10.shape[0])\n",
    "\n",
    "labels_neg_10 = np.zeros(TransE_score_neg_10.shape[0])\n",
    "labels_neg_20 = np.zeros(TransE_score_neg_20.shape[0])\n",
    "labels_neg_40 = np.zeros(TransE_score_neg_40.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some necessary post-processing on PaTyBRED values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dt_pos = pd.DataFrame({'Subject' : entities1_pos, 'Relation': relations_pos, 'Object' : entities2_pos})\n",
    "temp_dt_neg_10 = pd.DataFrame({'Subject' : entities1_neg_10, 'Relation': relations_neg_10, 'Object' : entities2_neg_10})\n",
    "temp_dt_neg_20 = pd.DataFrame({'Subject' : entities1_neg_20, 'Relation': relations_neg_20, 'Object' : entities2_neg_20})\n",
    "temp_dt_neg_40 = pd.DataFrame({'Subject' : entities1_neg_40, 'Relation': relations_neg_40, 'Object' : entities2_neg_40})\n",
    "\n",
    "PaTyBRED_10_pos_conf = np.asarray(pd.merge(temp_dt_pos, PaTyBRED_10)['Confidence'])\n",
    "#PaTyBRED_10_pos_conf = np.append(PaTyBRED_10_pos_conf, 0.0)\n",
    "PaTyBRED_10_neg_conf = np.asarray(pd.merge(temp_dt_neg_10, PaTyBRED_10)['Confidence'])\n",
    "PaTyBRED_20_pos_conf = np.asarray(pd.merge(temp_dt_pos, PaTyBRED_20)['Confidence'])\n",
    "#PaTyBRED_20_pos_conf = np.append(PaTyBRED_20_pos_conf, 0.0)\n",
    "PaTyBRED_20_neg_conf = np.asarray(pd.merge(temp_dt_neg_20, PaTyBRED_20)['Confidence'])\n",
    "PaTyBRED_40_pos_conf = np.asarray(pd.merge(temp_dt_pos, PaTyBRED_40)['Confidence'])\n",
    "#PaTyBRED_40_pos_conf = np.append(PaTyBRED_40_pos_conf, 0.0)\n",
    "PaTyBRED_40_neg_conf = np.asarray(pd.merge(temp_dt_neg_40, PaTyBRED_40)['Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_10 = np.random.choice(PaTyBRED_10_neg_conf, size = (TransE_score_neg_10.shape[0] - PaTyBRED_10_neg_conf.shape[0]), replace=False)\n",
    "PaTyBRED_10_neg_conf = np.concatenate((PaTyBRED_10_neg_conf, rest_10))\n",
    "\n",
    "rest_20 = np.random.choice(PaTyBRED_20_neg_conf, size = (TransE_score_neg_20.shape[0] - PaTyBRED_20_neg_conf.shape[0]), replace=False)\n",
    "PaTyBRED_20_neg_conf = np.concatenate((PaTyBRED_20_neg_conf, rest_20))\n",
    "\n",
    "rest_40 = np.random.choice(PaTyBRED_40_neg_conf, size = (TransE_score_neg_40.shape[0] - PaTyBRED_40_neg_conf.shape[0]), replace=False)\n",
    "PaTyBRED_40_neg_conf = np.concatenate((PaTyBRED_40_neg_conf, rest_40))\n",
    "\n",
    "rest_10 = np.random.choice(PaTyBRED_10_pos_conf, size = (TransE_score_pos_10.shape[0] - PaTyBRED_10_pos_conf.shape[0]), replace=False)\n",
    "PaTyBRED_10_pos_conf = np.concatenate((PaTyBRED_10_pos_conf, rest_10))\n",
    "\n",
    "rest_20 = np.random.choice(PaTyBRED_20_pos_conf, size = (TransE_score_pos_20.shape[0] - PaTyBRED_20_pos_conf.shape[0]), replace=False)\n",
    "PaTyBRED_20_pos_conf = np.concatenate((PaTyBRED_20_pos_conf, rest_20))\n",
    "\n",
    "rest_40 = np.random.choice(PaTyBRED_40_pos_conf, size = (TransE_score_pos_40.shape[0] - PaTyBRED_40_pos_conf.shape[0]), replace=False)\n",
    "PaTyBRED_40_pos_conf = np.concatenate((PaTyBRED_40_pos_conf, rest_40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the dictionary that will eventually become the global dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pos_10 = {'Label': labels_pos, 'Subject': train_dt_pos['e1'], 'Relation': train_dt_pos['r'], 'Object': train_dt_pos['e2'], 'TransE_Score': TransE_score_pos_10, 'CKRL_Score': CKRL_score_pos_10, 'PTransE_Score': PTransE_score_pos_10, 'PaTyBRED_Score': PaTyBRED_10_pos_conf, 'PRGE_Score': PRGE_score_pos_10, 'PRGE_Scaled_Score': PRGE_scaled_score_pos_10}\n",
    "d_pos_20 = {'Label': labels_pos, 'Subject': train_dt_pos['e1'], 'Relation': train_dt_pos['r'], 'Object': train_dt_pos['e2'], 'TransE_Score': TransE_score_pos_20, 'CKRL_Score': CKRL_score_pos_20, 'PTransE_Score': PTransE_score_pos_20, 'PaTyBRED_Score': PaTyBRED_20_pos_conf, 'PRGE_Score': PRGE_score_pos_20, 'PRGE_Scaled_Score': PRGE_scaled_score_pos_20}\n",
    "d_pos_40 = {'Label': labels_pos, 'Subject': train_dt_pos['e1'], 'Relation': train_dt_pos['r'], 'Object': train_dt_pos['e2'], 'TransE_Score': TransE_score_pos_40, 'CKRL_Score': CKRL_score_pos_40, 'PTransE_Score': PTransE_score_pos_40, 'PaTyBRED_Score': PaTyBRED_40_pos_conf, 'PRGE_Score': PRGE_score_pos_40, 'PRGE_Scaled_Score': PRGE_scaled_score_pos_40}\n",
    "\n",
    "d_neg_10 = {'Label': labels_neg_10, 'Subject': train_dt_neg_10['e1'], 'Relation': train_dt_neg_10['r'], 'Object': train_dt_neg_10['e2'], 'TransE_Score': TransE_score_neg_10, 'CKRL_Score': CKRL_score_neg_10, 'PTransE_Score': PTransE_score_neg_10, 'PaTyBRED_Score': PaTyBRED_10_neg_conf, 'PRGE_Score': PRGE_score_neg_10, 'PRGE_Scaled_Score': PRGE_scaled_score_neg_10}\n",
    "d_neg_20 = {'Label': labels_neg_20, 'Subject': train_dt_neg_20['e1'], 'Relation': train_dt_neg_20['r'], 'Object': train_dt_neg_20['e2'], 'TransE_Score': TransE_score_neg_20, 'CKRL_Score': CKRL_score_neg_20, 'PTransE_Score': PTransE_score_neg_20, 'PaTyBRED_Score': PaTyBRED_20_neg_conf, 'PRGE_Score': PRGE_score_neg_20, 'PRGE_Scaled_Score': PRGE_scaled_score_neg_20}\n",
    "d_neg_40 = {'Label': labels_neg_40, 'Subject': train_dt_neg_40['e1'], 'Relation': train_dt_neg_40['r'], 'Object': train_dt_neg_40['e2'], 'TransE_Score': TransE_score_neg_40, 'CKRL_Score': CKRL_score_neg_40, 'PTransE_Score': PTransE_score_neg_40, 'PaTyBRED_Score': PaTyBRED_40_neg_conf, 'PRGE_Score': PRGE_score_neg_40, 'PRGE_Scaled_Score': PRGE_scaled_score_neg_40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141442,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_pos_10['PaTyBRED_Score'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the final dataframee for each noise level (containing both positives and negatives):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdt_10 = pd.DataFrame(data=d_pos_10)\n",
    "posdt_20 = pd.DataFrame(data=d_pos_20)\n",
    "posdt_40 = pd.DataFrame(data=d_pos_40)\n",
    "\n",
    "negdt_10 = pd.DataFrame(data=d_neg_10)\n",
    "negdt_20 = pd.DataFrame(data=d_neg_20)\n",
    "negdt_40 = pd.DataFrame(data=d_neg_40)\n",
    "\n",
    "whole_data_10 = pd.concat([posdt_10, negdt_10])\n",
    "whole_data_20 = pd.concat([posdt_20, negdt_20])\n",
    "whole_data_40 = pd.concat([posdt_40, negdt_40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize every score in all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, column):\n",
    "    x = df[column]\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(np.asarray(x).reshape(-1, 1))\n",
    "    df[column] = 1-x_scaled\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['TransE_Score', 'PTransE_Score', 'CKRL_Score', 'PRGE_Score', 'PRGE_Scaled_Score']\n",
    "for column in columns_to_normalize:\n",
    "    whole_data_10 = normalize(whole_data_10, column)\n",
    "    whole_data_20 = normalize(whole_data_20, column)\n",
    "    whole_data_40 = normalize(whole_data_40, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dict_10 = {}\n",
    "auc_dict_20 = {}\n",
    "auc_dict_40 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc(df, column):\n",
    "    fpr, tpr, _ = roc_curve(np.asarray(df['Label']), np.asarray(df[column]))\n",
    "    return(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_calculate_auc = ['TransE_Score', 'PTransE_Score', 'CKRL_Score', 'PRGE_Score', 'PRGE_Scaled_Score', 'PaTyBRED_Score']\n",
    "for column in columns_to_calculate_auc:\n",
    "    auc_dict_10[column] = calc_auc(whole_data_10, column)\n",
    "    auc_dict_20[column] = calc_auc(whole_data_20, column)\n",
    "    auc_dict_40[column] = calc_auc(whole_data_40, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransE_Score': 0.7246915585424395,\n",
       " 'PTransE_Score': 0.6767670591185674,\n",
       " 'CKRL_Score': 0.8887391741776732,\n",
       " 'PRGE_Score': 0.9299233347294522,\n",
       " 'PRGE_Scaled_Score': 0.9739866518824275,\n",
       " 'PaTyBRED_Score': 0.9680054840943869}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_dict_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransE_Score': 0.7218850876224164,\n",
       " 'PTransE_Score': 0.6790944298941091,\n",
       " 'CKRL_Score': 0.8800395450184448,\n",
       " 'PRGE_Score': 0.9119872301847611,\n",
       " 'PRGE_Scaled_Score': 0.9726523164678296,\n",
       " 'PaTyBRED_Score': 0.9674503596962678}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_dict_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransE_Score': 0.6856541988078704,\n",
       " 'PTransE_Score': 0.6718802911549902,\n",
       " 'CKRL_Score': 0.7224943011182862,\n",
       " 'PRGE_Score': 0.8589257028255383,\n",
       " 'PRGE_Scaled_Score': 0.9740490667920676,\n",
       " 'PaTyBRED_Score': 0.9675097114569241}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_dict_40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fmR - fmRR Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_mR(error_array):\n",
    "    length = error_array.shape[0]\n",
    "    sum_fmr = 0\n",
    "    for i, rank_i in enumerate(error_array):\n",
    "        sum_fmr += rank_i - i + 1\n",
    "    return(sum_fmr/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_mRR(error_array):\n",
    "    length = error_array.shape[0]\n",
    "    sum_fmr = 0\n",
    "    for i, rank_i in enumerate(error_array):\n",
    "        sum_fmr += 1/(rank_i - i + 1)\n",
    "    return(sum_fmr/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filtered_scoring(df, column, fmR_dict, fmRR_dict):\n",
    "    df_of_interest = df[['Label', column]]\n",
    "    df_of_interest = df_of_interest.sort_values(column)\n",
    "    df_of_interest['Rank'] = df_of_interest[column].rank(ascending=True, method='first')\n",
    "    error_ranks = df_of_interest[df_of_interest['Label'] == 0.0]['Rank'].values\n",
    "    mean_rank_TransE_10 = error_ranks.mean()\n",
    "    fmR_dict[column] = filtered_mR(error_ranks)\n",
    "    fmRR_dict[column] = filtered_mRR(error_ranks)\n",
    "    return (fmR_dict, fmRR_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmR_dict_10 = {}\n",
    "fmR_dict_20 = {}\n",
    "fmR_dict_40 = {}\n",
    "fmRR_dict_10 = {}\n",
    "fmRR_dict_20 = {}\n",
    "fmRR_dict_40 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_calculate_fmR_fmRR = ['TransE_Score', 'PTransE_Score', 'CKRL_Score', 'PRGE_Score', 'PRGE_Scaled_Score', 'PaTyBRED_Score']\n",
    "for column in columns_to_calculate_fmR_fmRR:\n",
    "    fmR_dict_10, fmRR_dict_10 = apply_filtered_scoring(whole_data_10, column, fmR_dict_10, fmRR_dict_10)\n",
    "    fmR_dict_20, fmRR_dict_20 = apply_filtered_scoring(whole_data_20, column, fmR_dict_20, fmRR_dict_20)\n",
    "    fmR_dict_40, fmRR_dict_40 = apply_filtered_scoring(whole_data_40, column, fmR_dict_40, fmRR_dict_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TransE_Score': 38942.17639988688,\n",
       "  'PTransE_Score': 45720.713871606335,\n",
       "  'CKRL_Score': 15738.953832013574,\n",
       "  'PRGE_Score': 9913.783795248868,\n",
       "  'PRGE_Scaled_Score': 3681.3798076923076,\n",
       "  'PaTyBRED_Score': 4488.9178450226245},\n",
       " {'TransE_Score': 0.0002080382593638909,\n",
       "  'PTransE_Score': 0.0007499727674313539,\n",
       "  'CKRL_Score': 0.0009324488945768387,\n",
       "  'PRGE_Score': 0.0005526285356349966,\n",
       "  'PRGE_Scaled_Score': 0.0008668195522187066,\n",
       "  'PaTyBRED_Score': 0.0007904860309766775})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fmR_dict_10, fmRR_dict_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TransE_Score': 39339.12941883484,\n",
       "  'PTransE_Score': 45391.525593891405,\n",
       "  'CKRL_Score': 16969.446549773755,\n",
       "  'PRGE_Score': 12450.702135180996,\n",
       "  'PRGE_Scaled_Score': 3870.111071832579,\n",
       "  'PaTyBRED_Score': 4580.009473981901},\n",
       " {'TransE_Score': 0.00027021318232686253,\n",
       "  'PTransE_Score': 0.00030265529899114725,\n",
       "  'CKRL_Score': 0.0007427785719164714,\n",
       "  'PRGE_Score': 0.0003330832048485752,\n",
       "  'PRGE_Scaled_Score': 0.0008622793206736723,\n",
       "  'PaTyBRED_Score': 0.0007259343099671347})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fmR_dict_20, fmRR_dict_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TransE_Score': 44463.6988122172,\n",
       "  'PTransE_Score': 46411.90785845588,\n",
       "  'CKRL_Score': 39252.961061227375,\n",
       "  'PRGE_Score': 19955.830740950227,\n",
       "  'PRGE_Scaled_Score': 3672.55189479638,\n",
       "  'PaTyBRED_Score': 4583.398278421946},\n",
       " {'TransE_Score': 0.0005243697581528024,\n",
       "  'PTransE_Score': 0.00021618921763494415,\n",
       "  'CKRL_Score': 0.0011167670360566766,\n",
       "  'PRGE_Score': 0.0004016386220134414,\n",
       "  'PRGE_Scaled_Score': 0.0007965151847090079,\n",
       "  'PaTyBRED_Score': 0.0007065670841862847})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fmR_dict_40, fmRR_dict_40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.6",
   "language": "python",
   "name": "env3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
